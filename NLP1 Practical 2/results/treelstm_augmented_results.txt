TreeLSTMClassifier(
  (embed): Embedding(17581, 300, padding_idx=1)
  (treelstm): TreeLSTM(
    (reduce): TreeLSTMCell(300, 150)
    (proj_x): Linear(in_features=300, out_features=150, bias=True)
    (proj_x_gate): Linear(in_features=300, out_features=150, bias=True)
    (buffers_dropout): Dropout(p=0.5, inplace=False)
  )
  (output_layer): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=150, out_features=5, bias=True)
  )
)
Iter 250: loss=256.9883, time=8.50s
iter 250: dev acc=0.2352
new highscore
Iter 500: loss=215.2547, time=17.65s
iter 500: dev acc=0.2443
new highscore
Iter 750: loss=214.0257, time=26.70s
iter 750: dev acc=0.2470
new highscore
Iter 1000: loss=213.3622, time=36.28s
iter 1000: dev acc=0.2698
new highscore
Iter 1250: loss=210.1548, time=45.54s
iter 1250: dev acc=0.2707
new highscore
Iter 1500: loss=204.5318, time=54.62s
iter 1500: dev acc=0.2952
new highscore
Iter 1750: loss=201.1670, time=63.95s
iter 1750: dev acc=0.3061
new highscore
Iter 2000: loss=197.1936, time=73.02s
iter 2000: dev acc=0.2743
Iter 2250: loss=206.3590, time=82.53s
iter 2250: dev acc=0.3088
new highscore
Iter 2500: loss=194.7634, time=91.54s
iter 2500: dev acc=0.3015
Iter 2750: loss=206.7685, time=100.61s
iter 2750: dev acc=0.3006
Iter 3000: loss=196.5106, time=109.56s
iter 3000: dev acc=0.3188
new highscore
Iter 3250: loss=202.0251, time=118.91s
iter 3250: dev acc=0.3288
new highscore
Iter 3500: loss=191.9781, time=127.94s
iter 3500: dev acc=0.3143
Iter 3750: loss=191.2181, time=136.80s
iter 3750: dev acc=0.3324
new highscore
Iter 4000: loss=196.6153, time=146.05s
iter 4000: dev acc=0.3506
new highscore
Iter 4250: loss=195.5910, time=155.08s
iter 4250: dev acc=0.3315
Iter 4500: loss=186.7784, time=164.01s
iter 4500: dev acc=0.3588
new highscore
Iter 4750: loss=192.2738, time=173.13s
iter 4750: dev acc=0.3579
Iter 5000: loss=194.9163, time=182.00s
iter 5000: dev acc=0.3506
Iter 5250: loss=189.8283, time=191.23s
iter 5250: dev acc=0.3470
Iter 5500: loss=186.7317, time=200.19s
iter 5500: dev acc=0.3579
Iter 5750: loss=188.3390, time=209.14s
iter 5750: dev acc=0.3533
Iter 6000: loss=190.8218, time=218.23s
iter 6000: dev acc=0.3651
new highscore
Iter 6250: loss=190.6389, time=227.20s
iter 6250: dev acc=0.3597
Iter 6500: loss=186.3496, time=236.08s
iter 6500: dev acc=0.3506
Iter 6750: loss=181.1096, time=245.41s
iter 6750: dev acc=0.3451
Iter 7000: loss=186.7687, time=254.73s
iter 7000: dev acc=0.3261
Iter 7250: loss=184.6309, time=263.51s
iter 7250: dev acc=0.3824
new highscore
Iter 7500: loss=181.4716, time=272.65s
iter 7500: dev acc=0.3751
Iter 7750: loss=181.5264, time=281.85s
iter 7750: dev acc=0.3597
Iter 8000: loss=179.9868, time=290.82s
iter 8000: dev acc=0.3706
Iter 8250: loss=183.6694, time=299.91s
iter 8250: dev acc=0.3778
Iter 8500: loss=185.3984, time=309.36s
iter 8500: dev acc=0.3806
Iter 8750: loss=184.9814, time=318.83s
iter 8750: dev acc=0.3869
new highscore
Iter 9000: loss=181.9131, time=328.00s
iter 9000: dev acc=0.3942
new highscore
Iter 9250: loss=179.7441, time=336.82s
iter 9250: dev acc=0.3678
Iter 9500: loss=179.3338, time=346.57s
iter 9500: dev acc=0.3815
Iter 9750: loss=182.2223, time=355.93s
iter 9750: dev acc=0.3887
Iter 10000: loss=178.5531, time=365.15s
iter 10000: dev acc=0.3715
Done training
Loading best model
best model iter 9000: train acc=0.7361, dev acc=0.3942, test acc=0.3629
losses:
[256.98832139372826, 215.25468143820763, 214.02568325400352, 213.36224621534348, 210.15479642152786, 204.5317566692829, 201.16695821285248, 197.19362545013428, 206.35904440283775, 194.76344254612923, 206.76848584413528, 196.5106282234192, 202.0250819027424, 191.978098154068, 191.2181442528963, 196.61531761288643, 195.59104132652283, 186.77841106057167, 192.2737706899643, 194.91629526019096, 189.8282971382141, 186.73167836666107, 188.33898988366127, 190.8217537999153, 190.63891553878784, 186.3496429026127, 181.10955402255058, 186.76873302459717, 184.63086795806885, 181.47163566946983, 181.52641835808754, 179.98678514361382, 183.66942965984344, 185.39838939905167, 184.98143896460533, 181.91312456130981, 179.74407494068146, 179.3337536752224, 182.2222966849804, 178.55314111709595]
accuracies:
[0.23524069028156222, 0.24432334241598547, 0.24704813805631246, 0.26975476839237056, 0.2706630336058129, 0.29518619436875565, 0.3060853769300636, 0.2742960944595822, 0.30881017257039056, 0.30154405086285196, 0.3006357856494096, 0.3188010899182561, 0.32879200726612173, 0.3142597638510445, 0.33242506811989103, 0.3505903723887375, 0.3315168029064487, 0.35876475930971846, 0.3578564940962761, 0.3505903723887375, 0.3469573115349682, 0.3578564940962761, 0.3533151680290645, 0.3651226158038147, 0.35967302452316074, 0.3505903723887375, 0.34514078110808355, 0.3260672116257947, 0.3823796548592189, 0.3751135331516803, 0.35967302452316074, 0.37057220708446864, 0.37783832879200724, 0.38056312443233425, 0.3869209809264305, 0.3941871026339691, 0.3678474114441417, 0.3814713896457766, 0.3887375113533152, 0.371480472297911]

TreeLSTMClassifier(
  (embed): Embedding(17581, 300, padding_idx=1)
  (treelstm): TreeLSTM(
    (reduce): TreeLSTMCell(300, 150)
    (proj_x): Linear(in_features=300, out_features=150, bias=True)
    (proj_x_gate): Linear(in_features=300, out_features=150, bias=True)
    (buffers_dropout): Dropout(p=0.5, inplace=False)
  )
  (output_layer): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=150, out_features=5, bias=True)
  )
)
Iter 250: loss=257.4552, time=8.11s
iter 250: dev acc=0.2652
new highscore
Iter 500: loss=223.0822, time=17.36s
iter 500: dev acc=0.2470
Iter 750: loss=214.1267, time=26.55s
iter 750: dev acc=0.2743
new highscore
Iter 1000: loss=208.3769, time=35.67s
iter 1000: dev acc=0.2707
Iter 1250: loss=202.9201, time=44.75s
iter 1250: dev acc=0.2779
new highscore
Iter 1500: loss=209.1777, time=53.91s
iter 1500: dev acc=0.2670
Iter 1750: loss=203.2653, time=62.92s
iter 1750: dev acc=0.2961
new highscore
Iter 2000: loss=200.7037, time=72.65s
iter 2000: dev acc=0.3279
new highscore
Iter 2250: loss=199.0720, time=81.91s
iter 2250: dev acc=0.3243
Iter 2500: loss=197.5611, time=90.95s
iter 2500: dev acc=0.3415
new highscore
Iter 2750: loss=203.3149, time=100.17s
iter 2750: dev acc=0.3297
Iter 3000: loss=197.6943, time=109.35s
iter 3000: dev acc=0.3333
Iter 3250: loss=194.9658, time=118.44s
iter 3250: dev acc=0.3406
Iter 3500: loss=199.9118, time=127.48s
iter 3500: dev acc=0.3261
Iter 3750: loss=194.2701, time=136.79s
iter 3750: dev acc=0.3497
new highscore
Iter 4000: loss=193.3031, time=145.88s
iter 4000: dev acc=0.3388
Iter 4250: loss=194.0229, time=155.25s
iter 4250: dev acc=0.3633
new highscore
Iter 4500: loss=191.7347, time=164.32s
iter 4500: dev acc=0.3551
Iter 4750: loss=192.9720, time=173.46s
iter 4750: dev acc=0.3479
Iter 5000: loss=189.4897, time=182.67s
iter 5000: dev acc=0.3388
Iter 5250: loss=191.4977, time=191.83s
iter 5250: dev acc=0.3497
Iter 5500: loss=195.2101, time=200.77s
iter 5500: dev acc=0.3724
new highscore
Iter 5750: loss=181.4946, time=209.86s
iter 5750: dev acc=0.3442
Iter 6000: loss=187.9284, time=219.06s
iter 6000: dev acc=0.3261
Iter 6250: loss=189.8077, time=228.41s
iter 6250: dev acc=0.3597
Iter 6500: loss=187.3628, time=237.51s
iter 6500: dev acc=0.3751
new highscore
Iter 6750: loss=184.7252, time=246.70s
iter 6750: dev acc=0.3669
Iter 7000: loss=185.6654, time=255.59s
iter 7000: dev acc=0.3669
Iter 7250: loss=184.8327, time=264.85s
iter 7250: dev acc=0.3533
Iter 7500: loss=185.8420, time=274.13s
iter 7500: dev acc=0.3569
Iter 7750: loss=183.4655, time=283.17s
iter 7750: dev acc=0.3651
Iter 8000: loss=180.2485, time=292.02s
iter 8000: dev acc=0.3769
new highscore
Iter 8250: loss=185.7937, time=301.37s
iter 8250: dev acc=0.3688
Iter 8500: loss=178.9357, time=310.59s
iter 8500: dev acc=0.3706
Iter 8750: loss=178.8793, time=319.84s
iter 8750: dev acc=0.3751
Iter 9000: loss=178.1175, time=329.47s
iter 9000: dev acc=0.3797
new highscore
Iter 9250: loss=184.2363, time=338.52s
iter 9250: dev acc=0.3724
Iter 9500: loss=180.4307, time=347.76s
iter 9500: dev acc=0.3842
new highscore
Iter 9750: loss=184.6407, time=356.85s
iter 9750: dev acc=0.3851
new highscore
Iter 10000: loss=170.0013, time=366.03s
iter 10000: dev acc=0.3606
Done training
Loading best model
best model iter 9750: train acc=0.7381, dev acc=0.3851, test acc=0.3475
losses:
[257.45515245199203, 223.08216747641563, 214.12667658925056, 208.3768552839756, 202.92013773322105, 209.17770433425903, 203.2653458416462, 200.7036530971527, 199.07201850414276, 197.56106156110764, 203.3149492740631, 197.69429394602776, 194.96581435203552, 199.91181713342667, 194.27005672454834, 193.3030542731285, 194.02287003397942, 191.73474061489105, 192.97197461128235, 189.48967942595482, 191.49772641062737, 195.21012577414513, 181.49459728598595, 187.92843979597092, 189.80773621797562, 187.36283886432648, 184.72519320249557, 185.66541761159897, 184.83272850513458, 185.84201660752296, 183.46554300189018, 180.24849453568459, 185.7936515212059, 178.93569350242615, 178.87933951616287, 178.11751797795296, 184.2362799346447, 180.4306608736515, 184.64073306322098, 170.00127625465393]
accuracies:
[0.2652134423251589, 0.24704813805631246, 0.2742960944595822, 0.2706630336058129, 0.2779291553133515, 0.2670299727520436, 0.296094459582198, 0.3278837420526794, 0.3242506811989101, 0.34150772025431425, 0.329700272479564, 0.3333333333333333, 0.3405994550408719, 0.3260672116257947, 0.3496821071752952, 0.3387829246139873, 0.36330608537693004, 0.35513169845594916, 0.3478655767484105, 0.3387829246139873, 0.3496821071752952, 0.3723887375113533, 0.3442325158946412, 0.3260672116257947, 0.35967302452316074, 0.3751135331516803, 0.36693914623069934, 0.36693914623069934, 0.3533151680290645, 0.3569482288828338, 0.3651226158038147, 0.37693006357856496, 0.368755676657584, 0.37057220708446864, 0.3751135331516803, 0.3796548592188919, 0.3723887375113533, 0.38419618528610355, 0.3851044504995459, 0.3605812897366031]

TreeLSTMClassifier(
  (embed): Embedding(17581, 300, padding_idx=1)
  (treelstm): TreeLSTM(
    (reduce): TreeLSTMCell(300, 150)
    (proj_x): Linear(in_features=300, out_features=150, bias=True)
    (proj_x_gate): Linear(in_features=300, out_features=150, bias=True)
    (buffers_dropout): Dropout(p=0.5, inplace=False)
  )
  (output_layer): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=150, out_features=5, bias=True)
  )
)
Iter 250: loss=258.5789, time=8.52s
iter 250: dev acc=0.2552
new highscore
Iter 500: loss=219.0818, time=17.62s
iter 500: dev acc=0.2452
Iter 750: loss=215.3477, time=26.78s
iter 750: dev acc=0.2725
new highscore
Iter 1000: loss=208.3392, time=35.98s
iter 1000: dev acc=0.2670
Iter 1250: loss=207.5223, time=45.22s
iter 1250: dev acc=0.2970
new highscore
Iter 1500: loss=204.7342, time=54.34s
iter 1500: dev acc=0.3124
new highscore
Iter 1750: loss=205.5597, time=63.54s
iter 1750: dev acc=0.3279
new highscore
Iter 2000: loss=203.0692, time=73.25s
iter 2000: dev acc=0.3124
Iter 2250: loss=198.1915, time=82.51s
iter 2250: dev acc=0.3134
Iter 2500: loss=199.3783, time=91.83s
iter 2500: dev acc=0.3361
new highscore
Iter 2750: loss=199.5277, time=100.99s
iter 2750: dev acc=0.3497
new highscore
Iter 3000: loss=198.3345, time=110.24s
iter 3000: dev acc=0.3460
Iter 3250: loss=199.5930, time=119.63s
iter 3250: dev acc=0.3270
Iter 3500: loss=194.1955, time=128.50s
iter 3500: dev acc=0.3297
Iter 3750: loss=196.3170, time=137.45s
iter 3750: dev acc=0.3388
Iter 4000: loss=191.9954, time=146.39s
iter 4000: dev acc=0.3288
Iter 4250: loss=191.1607, time=155.67s
iter 4250: dev acc=0.2861
Iter 4500: loss=190.5220, time=164.99s
iter 4500: dev acc=0.3633
new highscore
Iter 4750: loss=191.5893, time=174.14s
iter 4750: dev acc=0.3415
Iter 5000: loss=187.0359, time=183.08s
iter 5000: dev acc=0.3542
Iter 5250: loss=193.1924, time=192.16s
iter 5250: dev acc=0.3624
Iter 5500: loss=188.2470, time=201.32s
iter 5500: dev acc=0.3524
Iter 5750: loss=189.7482, time=210.53s
iter 5750: dev acc=0.3451
Iter 6000: loss=186.1118, time=219.79s
iter 6000: dev acc=0.3615
Iter 6250: loss=190.8176, time=228.99s
iter 6250: dev acc=0.3797
new highscore
Iter 6500: loss=185.5188, time=237.79s
iter 6500: dev acc=0.3769
Iter 6750: loss=186.1608, time=246.79s
iter 6750: dev acc=0.3651
Iter 7000: loss=185.0049, time=256.07s
iter 7000: dev acc=0.3651
Iter 7250: loss=184.4028, time=265.31s
iter 7250: dev acc=0.3660
Iter 7500: loss=187.0523, time=274.26s
iter 7500: dev acc=0.3606
Iter 7750: loss=183.7176, time=283.07s
iter 7750: dev acc=0.3933
new highscore
Iter 8000: loss=181.1811, time=292.42s
iter 8000: dev acc=0.3388
Iter 8250: loss=185.3579, time=301.29s
iter 8250: dev acc=0.3678
Iter 8500: loss=179.0344, time=310.29s
iter 8500: dev acc=0.3842
Iter 8750: loss=180.9023, time=319.33s
iter 8750: dev acc=0.3778
Iter 9000: loss=177.5478, time=328.81s
iter 9000: dev acc=0.3906
Iter 9250: loss=177.8751, time=337.64s
iter 9250: dev acc=0.3724
Iter 9500: loss=174.4467, time=346.83s
iter 9500: dev acc=0.3851
Iter 9750: loss=179.7758, time=355.75s
iter 9750: dev acc=0.3869
Iter 10000: loss=176.0768, time=364.99s
iter 10000: dev acc=0.3851
Done training
Loading best model
best model iter 7750: train acc=0.7311, dev acc=0.3933, test acc=0.3692
losses:
[258.5788823366165, 219.0817632675171, 215.34769135713577, 208.33921638131142, 207.52229076623917, 204.7342345714569, 205.55971610546112, 203.06918260455132, 198.19152799248695, 199.3782731294632, 199.5276933312416, 198.3345088660717, 199.59304532408714, 194.1955056488514, 196.31702613830566, 191.99539986252785, 191.1606977880001, 190.5219714641571, 191.5893293619156, 187.03585875034332, 193.1923971772194, 188.2469671368599, 189.74822601675987, 186.11175644397736, 190.81760531663895, 185.5188158750534, 186.1607596874237, 185.00485208630562, 184.40275311470032, 187.05232641100883, 183.71758490800858, 181.18110111355782, 185.35790938138962, 179.03444927930832, 180.9023361802101, 177.54779756069183, 177.87514081597328, 174.4466945528984, 179.77582123875618, 176.07675802707672]
accuracies:
[0.25522252497729336, 0.2452316076294278, 0.2724795640326976, 0.2670299727520436, 0.2970027247956403, 0.31244323342415986, 0.3278837420526794, 0.31244323342415986, 0.3133514986376022, 0.33605812897366033, 0.3496821071752952, 0.3460490463215259, 0.32697547683923706, 0.329700272479564, 0.3387829246139873, 0.32879200726612173, 0.28610354223433243, 0.36330608537693004, 0.34150772025431425, 0.3542234332425068, 0.36239782016348776, 0.35240690281562215, 0.34514078110808355, 0.3614895549500454, 0.3796548592188919, 0.37693006357856496, 0.3651226158038147, 0.3651226158038147, 0.36603088101725706, 0.3605812897366031, 0.3932788374205268, 0.3387829246139873, 0.3678474114441417, 0.38419618528610355, 0.37783832879200724, 0.3905540417801998, 0.3723887375113533, 0.3851044504995459, 0.3869209809264305, 0.3851044504995459]


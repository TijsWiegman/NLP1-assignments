CBOW(
  (embed): Embedding(18280, 300)
  (linear): Linear(in_features=300, out_features=5, bias=True)
)
Iter 1000: loss=2711.8293, time=1.18s
iter 1000: dev acc=0.2162
new highscore
Iter 2000: loss=2302.4837, time=2.47s
iter 2000: dev acc=0.2371
new highscore
Iter 3000: loss=2064.9382, time=3.73s
iter 3000: dev acc=0.2425
new highscore
Iter 4000: loss=2036.7984, time=4.98s
iter 4000: dev acc=0.2552
new highscore
Iter 5000: loss=1915.4874, time=6.23s
iter 5000: dev acc=0.2352
Iter 6000: loss=1920.0500, time=7.43s
iter 6000: dev acc=0.2525
Iter 7000: loss=1898.1860, time=8.63s
iter 7000: dev acc=0.2498
Iter 8000: loss=1817.5787, time=9.82s
iter 8000: dev acc=0.2661
new highscore
Iter 9000: loss=1668.9951, time=11.06s
iter 9000: dev acc=0.2825
new highscore
Iter 10000: loss=1619.8958, time=12.30s
iter 10000: dev acc=0.3170
new highscore
Iter 11000: loss=1560.8292, time=13.54s
iter 11000: dev acc=0.2997
Iter 12000: loss=1642.1082, time=14.73s
iter 12000: dev acc=0.2970
Iter 13000: loss=1658.6307, time=15.93s
iter 13000: dev acc=0.2616
Iter 14000: loss=1594.1294, time=17.13s
iter 14000: dev acc=0.2834
Iter 15000: loss=1595.0119, time=18.32s
iter 15000: dev acc=0.3106
Iter 16000: loss=1615.8609, time=19.52s
iter 16000: dev acc=0.2925
Iter 17000: loss=1614.6074, time=20.71s
iter 17000: dev acc=0.3052
Iter 18000: loss=1224.7245, time=21.92s
iter 18000: dev acc=0.3279
new highscore
Iter 19000: loss=1309.4257, time=23.15s
iter 19000: dev acc=0.2997
Iter 20000: loss=1291.6873, time=24.35s
iter 20000: dev acc=0.2970
Iter 21000: loss=1271.6679, time=25.54s
iter 21000: dev acc=0.3152
Iter 22000: loss=1317.1683, time=26.73s
iter 22000: dev acc=0.3015
Iter 23000: loss=1353.9255, time=27.92s
iter 23000: dev acc=0.3188
Iter 24000: loss=1343.9496, time=29.12s
iter 24000: dev acc=0.3224
Iter 25000: loss=1315.8933, time=30.31s
iter 25000: dev acc=0.3134
Iter 26000: loss=1209.5902, time=31.51s
iter 26000: dev acc=0.3233
Iter 27000: loss=983.6076, time=32.70s
iter 27000: dev acc=0.3233
Iter 28000: loss=978.2582, time=33.90s
iter 28000: dev acc=0.3088
Iter 29000: loss=1058.9246, time=35.09s
iter 29000: dev acc=0.2970
Iter 30000: loss=1032.5375, time=36.28s
iter 30000: dev acc=0.3043
Done training
Loading best model
best model iter 18000: train acc=0.5446, dev acc=0.3279, test acc=0.2873
losses:
[2711.8292988082394, 2302.48365662992, 2064.9382396675646, 2036.7983962595463, 1915.4873706139624, 1920.0499521186575, 1898.1860219854861, 1817.5786504541757, 1668.9950658138841, 1619.8958234144375, 1560.8291901880875, 1642.1081676152535, 1658.6306684102165, 1594.1293826256297, 1595.0118928344455, 1615.8609160822816, 1614.6074287004594, 1224.7245472155046, 1309.4256594168255, 1291.6873137701768, 1271.66790386074, 1317.1682909363299, 1353.9255071791777, 1343.9496266420065, 1315.8932916630001, 1209.590173241566, 983.6076264142821, 978.2582279238704, 1058.9246447186233, 1032.5374821439764]
accuracies:
[0.2161671207992734, 0.23705722070844687, 0.24250681198910082, 0.25522252497729336, 0.23524069028156222, 0.2524977293369664, 0.24977293369663942, 0.26612170753860126, 0.28247048138056313, 0.3169845594913715, 0.2997275204359673, 0.2970027247956403, 0.2615803814713896, 0.28337874659400547, 0.3106267029972752, 0.2924613987284287, 0.30517711171662126, 0.3278837420526794, 0.2997275204359673, 0.2970027247956403, 0.3151680290644868, 0.30154405086285196, 0.3188010899182561, 0.3224341507720254, 0.3133514986376022, 0.32334241598546776, 0.32334241598546776, 0.30881017257039056, 0.2970027247956403, 0.3042688465031789]

CBOW(
  (embed): Embedding(18280, 300)
  (linear): Linear(in_features=300, out_features=5, bias=True)
)
Iter 1000: loss=2740.9523, time=1.00s
iter 1000: dev acc=0.2307
new highscore
Iter 2000: loss=2392.6687, time=2.25s
iter 2000: dev acc=0.2461
new highscore
Iter 3000: loss=2131.4758, time=3.50s
iter 3000: dev acc=0.2616
new highscore
Iter 4000: loss=1981.0313, time=4.75s
iter 4000: dev acc=0.2788
new highscore
Iter 5000: loss=1931.1791, time=5.99s
iter 5000: dev acc=0.2906
new highscore
Iter 6000: loss=1861.5017, time=7.24s
iter 6000: dev acc=0.3079
new highscore
Iter 7000: loss=1923.5578, time=8.48s
iter 7000: dev acc=0.3079
Iter 8000: loss=1825.5913, time=9.67s
iter 8000: dev acc=0.2725
Iter 9000: loss=1737.0660, time=10.87s
iter 9000: dev acc=0.2797
Iter 10000: loss=1588.4396, time=12.06s
iter 10000: dev acc=0.3006
Iter 11000: loss=1582.8517, time=13.25s
iter 11000: dev acc=0.3279
new highscore
Iter 12000: loss=1566.3646, time=14.49s
iter 12000: dev acc=0.3006
Iter 13000: loss=1631.6426, time=15.69s
iter 13000: dev acc=0.3061
Iter 14000: loss=1706.7363, time=16.88s
iter 14000: dev acc=0.3188
Iter 15000: loss=1677.0166, time=18.08s
iter 15000: dev acc=0.3025
Iter 16000: loss=1674.9979, time=19.27s
iter 16000: dev acc=0.3152
Iter 17000: loss=1635.6096, time=20.46s
iter 17000: dev acc=0.3188
Iter 18000: loss=1262.0031, time=21.65s
iter 18000: dev acc=0.3297
new highscore
Iter 19000: loss=1308.1617, time=22.90s
iter 19000: dev acc=0.3397
new highscore
Iter 20000: loss=1345.0601, time=24.14s
iter 20000: dev acc=0.3470
new highscore
Iter 21000: loss=1366.9005, time=25.38s
iter 21000: dev acc=0.3379
Iter 22000: loss=1384.0652, time=26.58s
iter 22000: dev acc=0.3206
Iter 23000: loss=1412.8849, time=27.77s
iter 23000: dev acc=0.3097
Iter 24000: loss=1293.3457, time=28.96s
iter 24000: dev acc=0.3379
Iter 25000: loss=1337.9151, time=30.16s
iter 25000: dev acc=0.3206
Iter 26000: loss=1294.2463, time=31.36s
iter 26000: dev acc=0.3243
Iter 27000: loss=949.9523, time=32.55s
iter 27000: dev acc=0.3297
Iter 28000: loss=982.3842, time=33.74s
iter 28000: dev acc=0.3015
Iter 29000: loss=1069.0428, time=34.93s
iter 29000: dev acc=0.3197
Iter 30000: loss=1076.7962, time=36.12s
iter 30000: dev acc=0.3324
Done training
Loading best model
best model iter 20000: train acc=0.5592, dev acc=0.3470, test acc=0.3249
losses:
[2740.952317433548, 2392.6686967527494, 2131.4757816093042, 1981.0313199809752, 1931.1790849156678, 1861.5016989898868, 1923.5578044764698, 1825.5912827015854, 1737.0659816656262, 1588.4395797969773, 1582.8516929291654, 1566.3645832983311, 1631.6425568412524, 1706.7362987607485, 1677.016604188364, 1674.9978991032112, 1635.6096122409217, 1262.0030905276071, 1308.161735318019, 1345.0600625554289, 1366.900544520824, 1384.0651608472108, 1412.884877706645, 1293.3457086750423, 1337.9151319656958, 1294.2462725996156, 949.95231075232, 982.3841871600016, 1069.0427800011712, 1076.7961791004072]
accuracies:
[0.23069936421435058, 0.24613987284287012, 0.2615803814713896, 0.27883742052679383, 0.29064486830154407, 0.3079019073569482, 0.3079019073569482, 0.2724795640326976, 0.27974568574023617, 0.3006357856494096, 0.3278837420526794, 0.3006357856494096, 0.3060853769300636, 0.3188010899182561, 0.3024523160762943, 0.3151680290644868, 0.3188010899182561, 0.329700272479564, 0.33969118982742963, 0.3469573115349682, 0.33787465940054495, 0.3206176203451408, 0.3097184377838329, 0.33787465940054495, 0.3206176203451408, 0.3242506811989101, 0.329700272479564, 0.30154405086285196, 0.31970935513169846, 0.33242506811989103]

CBOW(
  (embed): Embedding(18280, 300)
  (linear): Linear(in_features=300, out_features=5, bias=True)
)
Iter 1000: loss=2725.6991, time=0.99s
iter 1000: dev acc=0.2570
new highscore
Iter 2000: loss=2242.7117, time=2.24s
iter 2000: dev acc=0.2516
Iter 3000: loss=2098.9892, time=3.44s
iter 3000: dev acc=0.2679
new highscore
Iter 4000: loss=2050.3730, time=4.69s
iter 4000: dev acc=0.2516
Iter 5000: loss=1941.7911, time=5.89s
iter 5000: dev acc=0.2688
new highscore
Iter 6000: loss=1910.3903, time=7.14s
iter 6000: dev acc=0.2743
new highscore
Iter 7000: loss=1964.4931, time=8.39s
iter 7000: dev acc=0.2988
new highscore
Iter 8000: loss=1909.0999, time=9.63s
iter 8000: dev acc=0.3233
new highscore
Iter 9000: loss=1740.1635, time=10.88s
iter 9000: dev acc=0.2934
Iter 10000: loss=1583.9568, time=12.08s
iter 10000: dev acc=0.3170
Iter 11000: loss=1598.1602, time=13.27s
iter 11000: dev acc=0.2879
Iter 12000: loss=1636.5006, time=14.47s
iter 12000: dev acc=0.3115
Iter 13000: loss=1663.0225, time=15.67s
iter 13000: dev acc=0.3288
new highscore
Iter 14000: loss=1646.2336, time=16.91s
iter 14000: dev acc=0.3215
Iter 15000: loss=1587.2522, time=18.10s
iter 15000: dev acc=0.3052
Iter 16000: loss=1653.3590, time=19.30s
iter 16000: dev acc=0.3179
Iter 17000: loss=1654.1720, time=20.49s
iter 17000: dev acc=0.3034
Iter 18000: loss=1254.6452, time=21.70s
iter 18000: dev acc=0.3179
Iter 19000: loss=1318.6422, time=22.89s
iter 19000: dev acc=0.3279
Iter 20000: loss=1286.3913, time=24.09s
iter 20000: dev acc=0.3188
Iter 21000: loss=1301.9149, time=25.29s
iter 21000: dev acc=0.3379
new highscore
Iter 22000: loss=1369.5986, time=26.53s
iter 22000: dev acc=0.3306
Iter 23000: loss=1410.8889, time=27.72s
iter 23000: dev acc=0.3179
Iter 24000: loss=1384.1776, time=28.91s
iter 24000: dev acc=0.3161
Iter 25000: loss=1331.6381, time=30.11s
iter 25000: dev acc=0.3460
new highscore
Iter 26000: loss=1216.3036, time=31.36s
iter 26000: dev acc=0.3460
Iter 27000: loss=974.5593, time=32.55s
iter 27000: dev acc=0.3361
Iter 28000: loss=1046.3643, time=33.74s
iter 28000: dev acc=0.3451
Iter 29000: loss=1068.5872, time=34.94s
iter 29000: dev acc=0.3370
Iter 30000: loss=1012.2111, time=36.13s
iter 30000: dev acc=0.3460
Done training
Loading best model
best model iter 25000: train acc=0.6441, dev acc=0.3460, test acc=0.3267
losses:
[2725.6990613969974, 2242.711652540951, 2098.989203287405, 2050.3729562453227, 1941.7910852220375, 1910.3902884535491, 1964.4930843221955, 1909.0998851892073, 1740.1635180069134, 1583.9567835410126, 1598.160247203894, 1636.500552260317, 1663.0225417821202, 1646.2336242342135, 1587.25218466777, 1653.3589872947196, 1654.171997819678, 1254.6452193349833, 1318.6422052333364, 1286.3913009387034, 1301.914917928665, 1369.5986315268674, 1410.888941777297, 1384.1775529517035, 1331.6381365259876, 1216.3036159944895, 974.5593302670604, 1046.3642647222587, 1068.5871659923723, 1012.2111136030217]
accuracies:
[0.25703905540417804, 0.25158946412352406, 0.26793823796548594, 0.25158946412352406, 0.2688465031789282, 0.2742960944595822, 0.298819255222525, 0.32334241598546776, 0.29336966394187103, 0.3169845594913715, 0.28792007266121705, 0.3115349682107175, 0.32879200726612173, 0.3215258855585831, 0.30517711171662126, 0.3178928247048138, 0.3033605812897366, 0.3178928247048138, 0.3278837420526794, 0.3188010899182561, 0.33787465940054495, 0.33060853769300635, 0.3178928247048138, 0.31607629427792916, 0.3460490463215259, 0.3460490463215259, 0.33605812897366033, 0.34514078110808355, 0.3369663941871026, 0.3460490463215259]


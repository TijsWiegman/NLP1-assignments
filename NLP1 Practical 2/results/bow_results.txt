BOW(
  (embed): Embedding(18280, 5)
)
Iter 1000: loss=5511.9492, time=0.71s
iter 1000: dev acc=0.1862
new highscore
Iter 2000: loss=5230.9143, time=1.62s
iter 2000: dev acc=0.1916
new highscore
Iter 3000: loss=5277.6558, time=2.53s
iter 3000: dev acc=0.1998
new highscore
Iter 4000: loss=5001.1119, time=3.44s
iter 4000: dev acc=0.1998
Iter 5000: loss=4836.5083, time=4.35s
iter 5000: dev acc=0.2044
new highscore
Iter 6000: loss=4987.0862, time=5.25s
iter 6000: dev acc=0.2116
new highscore
Iter 7000: loss=4643.6971, time=6.15s
iter 7000: dev acc=0.2153
new highscore
Iter 8000: loss=4586.7165, time=7.04s
iter 8000: dev acc=0.2198
new highscore
Iter 9000: loss=4420.7300, time=7.92s
iter 9000: dev acc=0.2243
new highscore
Iter 10000: loss=4256.6649, time=8.80s
iter 10000: dev acc=0.2171
Iter 11000: loss=4332.6827, time=9.67s
iter 11000: dev acc=0.2198
Iter 12000: loss=4154.0794, time=10.54s
iter 12000: dev acc=0.2225
Iter 13000: loss=4077.2174, time=11.42s
iter 13000: dev acc=0.2162
Iter 14000: loss=3999.4425, time=12.29s
iter 14000: dev acc=0.2189
Iter 15000: loss=4203.7797, time=13.16s
iter 15000: dev acc=0.2198
Iter 16000: loss=3853.8267, time=14.04s
iter 16000: dev acc=0.2252
new highscore
Iter 17000: loss=4000.1410, time=14.92s
iter 17000: dev acc=0.2243
Iter 18000: loss=3652.2357, time=15.79s
iter 18000: dev acc=0.2262
new highscore
Iter 19000: loss=3678.5321, time=16.67s
iter 19000: dev acc=0.2234
Iter 20000: loss=3484.3529, time=17.55s
iter 20000: dev acc=0.2289
new highscore
Iter 21000: loss=3676.2877, time=18.42s
iter 21000: dev acc=0.2307
new highscore
Iter 22000: loss=3452.3079, time=19.30s
iter 22000: dev acc=0.2271
Iter 23000: loss=3541.2674, time=20.17s
iter 23000: dev acc=0.2252
Iter 24000: loss=3437.5871, time=21.04s
iter 24000: dev acc=0.2271
Iter 25000: loss=3331.1855, time=21.92s
iter 25000: dev acc=0.2280
Iter 26000: loss=3405.8278, time=22.80s
iter 26000: dev acc=0.2280
Iter 27000: loss=3343.8669, time=23.67s
iter 27000: dev acc=0.2352
new highscore
Iter 28000: loss=3113.7685, time=24.54s
iter 28000: dev acc=0.2334
Iter 29000: loss=3195.7524, time=25.42s
iter 29000: dev acc=0.2352
Iter 30000: loss=3220.1310, time=26.29s
iter 30000: dev acc=0.2316
Done training
Loading best model
best model iter 27000: train acc=0.3016, dev acc=0.2352, test acc=0.2140
losses:
[5511.949157896635, 5230.914323478897, 5277.655822327291, 5001.111944598805, 4836.508289691324, 4987.086175600018, 4643.697147152341, 4586.716505873235, 4420.729985621241, 4256.664891051424, 4332.682685815014, 4154.079356677335, 4077.217415471914, 3999.4424507103877, 4203.779691106038, 3853.8267430860287, 4000.140968081022, 3652.2356664635554, 3678.5320649147134, 3484.352935990489, 3676.2877333999027, 3452.307908015642, 3541.2674084813734, 3437.5871290278574, 3331.1854535982284, 3405.8278464907808, 3343.8668895946976, 3113.7684907590956, 3195.7523744574537, 3220.130968716443]
accuracies:
[0.18619436875567666, 0.1916439600363306, 0.19981834695731154, 0.19981834695731154, 0.20435967302452315, 0.21162579473206175, 0.21525885558583105, 0.2198001816530427, 0.22434150772025432, 0.21707538601271573, 0.2198001816530427, 0.22252497729336967, 0.2161671207992734, 0.21889191643960038, 0.2198001816530427, 0.22524977293369663, 0.22434150772025432, 0.22615803814713897, 0.22343324250681199, 0.22888283378746593, 0.23069936421435058, 0.22706630336058128, 0.22524977293369663, 0.22706630336058128, 0.22797456857402362, 0.22797456857402362, 0.23524069028156222, 0.23342415985467757, 0.23524069028156222, 0.23160762942779292]

BOW(
  (embed): Embedding(18280, 5)
)
Iter 1000: loss=5217.8039, time=0.70s
iter 1000: dev acc=0.2044
new highscore
Iter 2000: loss=5084.9938, time=1.60s
iter 2000: dev acc=0.2098
new highscore
Iter 3000: loss=4762.0839, time=2.51s
iter 3000: dev acc=0.2098
Iter 4000: loss=4702.0300, time=3.41s
iter 4000: dev acc=0.2153
new highscore
Iter 5000: loss=4659.2194, time=4.31s
iter 5000: dev acc=0.2280
new highscore
Iter 6000: loss=4409.9173, time=5.21s
iter 6000: dev acc=0.2289
new highscore
Iter 7000: loss=4572.5220, time=6.10s
iter 7000: dev acc=0.2289
Iter 8000: loss=4549.6576, time=6.99s
iter 8000: dev acc=0.2334
new highscore
Iter 9000: loss=4282.1145, time=7.87s
iter 9000: dev acc=0.2343
new highscore
Iter 10000: loss=4132.3829, time=8.74s
iter 10000: dev acc=0.2280
Iter 11000: loss=4064.2903, time=9.61s
iter 11000: dev acc=0.2289
Iter 12000: loss=4121.6996, time=10.48s
iter 12000: dev acc=0.2343
Iter 13000: loss=4196.6056, time=11.35s
iter 13000: dev acc=0.2334
Iter 14000: loss=3906.0350, time=12.22s
iter 14000: dev acc=0.2352
new highscore
Iter 15000: loss=3881.4163, time=13.10s
iter 15000: dev acc=0.2343
Iter 16000: loss=3920.1998, time=13.97s
iter 16000: dev acc=0.2389
new highscore
Iter 17000: loss=3724.7895, time=14.84s
iter 17000: dev acc=0.2352
Iter 18000: loss=3640.4201, time=15.72s
iter 18000: dev acc=0.2398
new highscore
Iter 19000: loss=3598.6508, time=16.59s
iter 19000: dev acc=0.2361
Iter 20000: loss=3650.5824, time=17.46s
iter 20000: dev acc=0.2434
new highscore
Iter 21000: loss=3603.2658, time=18.34s
iter 21000: dev acc=0.2470
new highscore
Iter 22000: loss=3567.8743, time=19.22s
iter 22000: dev acc=0.2443
Iter 23000: loss=3478.7007, time=20.10s
iter 23000: dev acc=0.2461
Iter 24000: loss=3375.8065, time=20.97s
iter 24000: dev acc=0.2498
new highscore
Iter 25000: loss=3222.8155, time=21.85s
iter 25000: dev acc=0.2480
Iter 26000: loss=3436.0986, time=22.73s
iter 26000: dev acc=0.2543
new highscore
Iter 27000: loss=3285.9005, time=23.60s
iter 27000: dev acc=0.2552
new highscore
Iter 28000: loss=3013.4614, time=24.47s
iter 28000: dev acc=0.2589
new highscore
Iter 29000: loss=3189.7715, time=25.35s
iter 29000: dev acc=0.2561
Iter 30000: loss=3133.4876, time=26.22s
iter 30000: dev acc=0.2607
new highscore
Done training
Loading best model
best model iter 30000: train acc=0.3134, dev acc=0.2607, test acc=0.2810
losses:
[5217.803931781764, 5084.993773808004, 4762.083921272995, 4702.029952803161, 4659.219368102651, 4409.9172659508795, 4572.522034787153, 4549.657558068582, 4282.114549848069, 4132.382854643685, 4064.2902877938686, 4121.6995611566745, 4196.605588791148, 3906.0349634216536, 3881.4163106434808, 3920.1998292121098, 3724.7894847700245, 3640.420055361749, 3598.650778838075, 3650.5824333332566, 3603.2657721961514, 3567.8743371276287, 3478.700743054669, 3375.8064828810657, 3222.815512652167, 3436.098600595644, 3285.9004637615726, 3013.461367624913, 3189.7715052783897, 3133.487637513057]
accuracies:
[0.20435967302452315, 0.2098092643051771, 0.2098092643051771, 0.21525885558583105, 0.22797456857402362, 0.22888283378746593, 0.22888283378746593, 0.23342415985467757, 0.23433242506811988, 0.22797456857402362, 0.22888283378746593, 0.23433242506811988, 0.23342415985467757, 0.23524069028156222, 0.23433242506811988, 0.23887375113533152, 0.23524069028156222, 0.23978201634877383, 0.23614895549500453, 0.24341507720254316, 0.24704813805631246, 0.24432334241598547, 0.24613987284287012, 0.24977293369663942, 0.24795640326975477, 0.254314259763851, 0.25522252497729336, 0.25885558583106266, 0.2561307901907357, 0.26067211625794734]

BOW(
  (embed): Embedding(18280, 5)
)
Iter 1000: loss=5431.1210, time=0.70s
iter 1000: dev acc=0.2234
new highscore
Iter 2000: loss=4923.7674, time=1.61s
iter 2000: dev acc=0.2271
new highscore
Iter 3000: loss=4737.8472, time=2.52s
iter 3000: dev acc=0.2189
Iter 4000: loss=5044.3003, time=3.42s
iter 4000: dev acc=0.2216
Iter 5000: loss=4924.0200, time=4.32s
iter 5000: dev acc=0.2234
Iter 6000: loss=4858.4721, time=5.22s
iter 6000: dev acc=0.2298
new highscore
Iter 7000: loss=4539.1989, time=6.12s
iter 7000: dev acc=0.2298
Iter 8000: loss=4469.9468, time=7.00s
iter 8000: dev acc=0.2307
new highscore
Iter 9000: loss=4303.7403, time=7.89s
iter 9000: dev acc=0.2343
new highscore
Iter 10000: loss=4200.5157, time=8.76s
iter 10000: dev acc=0.2371
new highscore
Iter 11000: loss=4338.2829, time=9.64s
iter 11000: dev acc=0.2371
Iter 12000: loss=4277.3598, time=10.52s
iter 12000: dev acc=0.2398
new highscore
Iter 13000: loss=3949.9605, time=11.40s
iter 13000: dev acc=0.2361
Iter 14000: loss=4148.5479, time=12.27s
iter 14000: dev acc=0.2371
Iter 15000: loss=4026.4710, time=13.15s
iter 15000: dev acc=0.2407
new highscore
Iter 16000: loss=3756.5356, time=14.02s
iter 16000: dev acc=0.2425
new highscore
Iter 17000: loss=3898.3678, time=14.89s
iter 17000: dev acc=0.2470
new highscore
Iter 18000: loss=3769.7555, time=15.75s
iter 18000: dev acc=0.2452
Iter 19000: loss=3535.1960, time=16.61s
iter 19000: dev acc=0.2480
new highscore
Iter 20000: loss=3907.3400, time=17.47s
iter 20000: dev acc=0.2480
Iter 21000: loss=3690.0682, time=18.33s
iter 21000: dev acc=0.2489
new highscore
Iter 22000: loss=3433.3460, time=19.18s
iter 22000: dev acc=0.2461
Iter 23000: loss=3542.8746, time=20.04s
iter 23000: dev acc=0.2416
Iter 24000: loss=3442.2528, time=20.90s
iter 24000: dev acc=0.2443
Iter 25000: loss=3336.9111, time=21.76s
iter 25000: dev acc=0.2498
new highscore
Iter 26000: loss=3279.8607, time=22.62s
iter 26000: dev acc=0.2507
new highscore
Iter 27000: loss=3019.9582, time=23.48s
iter 27000: dev acc=0.2516
new highscore
Iter 28000: loss=3195.8897, time=24.34s
iter 28000: dev acc=0.2552
new highscore
Iter 29000: loss=3241.6277, time=25.20s
iter 29000: dev acc=0.2552
Iter 30000: loss=3237.5089, time=26.05s
iter 30000: dev acc=0.2570
new highscore
Done training
Loading best model
best model iter 30000: train acc=0.3165, dev acc=0.2570, test acc=0.2425
losses:
[5431.120978742832, 4923.7673746895525, 4737.847171688558, 5044.300315426401, 4924.019964009513, 4858.472115960655, 4539.198919677809, 4469.946839899661, 4303.740266937504, 4200.515707478227, 4338.282902713916, 4277.359813934205, 3949.960457424342, 4148.547896347607, 4026.470974426604, 3756.5356225074756, 3898.367843865718, 3769.7554789650203, 3535.195956546082, 3907.340021554978, 3690.0682388084624, 3433.3460012202377, 3542.874551670262, 3442.2528292929146, 3336.9110795673423, 3279.8606567774177, 3019.9582483808535, 3195.889672304662, 3241.6277352964644, 3237.5089081683545]
accuracies:
[0.22343324250681199, 0.22706630336058128, 0.21889191643960038, 0.22161671207992734, 0.22343324250681199, 0.22979109900090827, 0.22979109900090827, 0.23069936421435058, 0.23433242506811988, 0.23705722070844687, 0.23705722070844687, 0.23978201634877383, 0.23614895549500453, 0.23705722070844687, 0.24069028156221617, 0.24250681198910082, 0.24704813805631246, 0.2452316076294278, 0.24795640326975477, 0.24795640326975477, 0.2488646684831971, 0.24613987284287012, 0.24159854677565848, 0.24432334241598547, 0.24977293369663942, 0.2506811989100817, 0.25158946412352406, 0.25522252497729336, 0.25522252497729336, 0.25703905540417804]


BOW(
  (embed): Embedding(18280, 5)
)
Iter 1000: loss=5795.7367, time=1.21s
iter 1000: dev acc=0.1907
new highscore
Iter 2000: loss=5473.1633, time=3.15s
iter 2000: dev acc=0.1935
new highscore
Iter 3000: loss=5040.9163, time=5.08s
iter 3000: dev acc=0.1980
new highscore
Iter 4000: loss=4990.8491, time=7.00s
iter 4000: dev acc=0.2035
new highscore
Iter 5000: loss=4951.4391, time=8.93s
iter 5000: dev acc=0.2116
new highscore
Iter 6000: loss=4753.0372, time=10.85s
iter 6000: dev acc=0.2144
new highscore
Iter 7000: loss=4578.1376, time=12.77s
iter 7000: dev acc=0.2144
Iter 8000: loss=4728.4490, time=14.68s
iter 8000: dev acc=0.2180
new highscore
Iter 9000: loss=4395.7212, time=16.59s
iter 9000: dev acc=0.2171
Iter 10000: loss=4385.3962, time=18.49s
iter 10000: dev acc=0.2171
Iter 11000: loss=4360.5084, time=20.39s
iter 11000: dev acc=0.2171
Iter 12000: loss=4229.0171, time=22.30s
iter 12000: dev acc=0.2189
new highscore
Iter 13000: loss=4139.5356, time=24.21s
iter 13000: dev acc=0.2207
new highscore
Iter 14000: loss=4142.7418, time=26.11s
iter 14000: dev acc=0.2180
Iter 15000: loss=3924.7356, time=28.01s
iter 15000: dev acc=0.2198
Iter 16000: loss=3784.2217, time=29.92s
iter 16000: dev acc=0.2262
new highscore
Iter 17000: loss=3780.0832, time=31.83s
iter 17000: dev acc=0.2189
Iter 18000: loss=3745.5436, time=33.74s
iter 18000: dev acc=0.2198
Iter 19000: loss=3755.2969, time=35.64s
iter 19000: dev acc=0.2234
Iter 20000: loss=3629.0431, time=37.55s
iter 20000: dev acc=0.2189
Iter 21000: loss=3516.1283, time=39.45s
iter 21000: dev acc=0.2262
Iter 22000: loss=3580.0305, time=41.36s
iter 22000: dev acc=0.2262
Iter 23000: loss=3483.0029, time=43.25s
iter 23000: dev acc=0.2225
Iter 24000: loss=3492.9823, time=45.16s
iter 24000: dev acc=0.2234
Iter 25000: loss=3242.1912, time=47.06s
iter 25000: dev acc=0.2225
Iter 26000: loss=3241.6007, time=48.96s
iter 26000: dev acc=0.2262
Iter 27000: loss=2936.3386, time=50.87s
iter 27000: dev acc=0.2271
new highscore
Iter 28000: loss=3233.4744, time=52.77s
iter 28000: dev acc=0.2243
Iter 29000: loss=3022.7356, time=54.67s
iter 29000: dev acc=0.2243
Iter 30000: loss=3217.0069, time=56.57s
iter 30000: dev acc=0.2334
new highscore
Done training
Loading best model
best model iter 30000: train acc=0.3114, dev acc=0.2334, test acc=0.2163
losses:
[5795.736710474085, 5473.163256328725, 5040.916341205867, 4990.849114547681, 4951.439104587333, 4753.037151977976, 4578.137599570771, 4728.449030364954, 4395.721171926465, 4385.396180081387, 4360.508371666554, 4229.017051859491, 4139.53556469951, 4142.74183832907, 3924.7355763373544, 3784.221668100393, 3780.083222487425, 3745.5436412888557, 3755.296899462141, 3629.0431081937495, 3516.128326234481, 3580.0305270882745, 3483.0029419713283, 3492.982321490769, 3242.191183502586, 3241.600651258752, 2936.338635905094, 3233.474434377207, 3022.735632912605, 3217.0069398094565]
accuracies:
[0.1907356948228883, 0.19346049046321526, 0.1980018165304269, 0.20345140781108084, 0.21162579473206175, 0.21435059037238874, 0.21435059037238874, 0.21798365122615804, 0.21707538601271573, 0.21707538601271573, 0.21707538601271573, 0.21889191643960038, 0.22070844686648503, 0.21798365122615804, 0.2198001816530427, 0.22615803814713897, 0.21889191643960038, 0.2198001816530427, 0.22343324250681199, 0.21889191643960038, 0.22615803814713897, 0.22615803814713897, 0.22252497729336967, 0.22343324250681199, 0.22252497729336967, 0.22615803814713897, 0.22706630336058128, 0.22434150772025432, 0.22434150772025432, 0.23342415985467757]

BOW(
  (embed): Embedding(18280, 5)
)
Iter 1000: loss=5250.5588, time=1.22s
iter 1000: dev acc=0.1989
new highscore
Iter 2000: loss=4960.6558, time=3.18s
iter 2000: dev acc=0.2071
new highscore
Iter 3000: loss=4653.3072, time=5.12s
iter 3000: dev acc=0.2071
Iter 4000: loss=4878.2032, time=7.04s
iter 4000: dev acc=0.2134
new highscore
Iter 5000: loss=4674.4023, time=8.96s
iter 5000: dev acc=0.2225
new highscore
Iter 6000: loss=4545.4360, time=10.87s
iter 6000: dev acc=0.2280
new highscore
Iter 7000: loss=4379.3546, time=12.79s
iter 7000: dev acc=0.2316
new highscore
Iter 8000: loss=4478.0024, time=14.69s
iter 8000: dev acc=0.2334
new highscore
Iter 9000: loss=4317.0348, time=16.60s
iter 9000: dev acc=0.2334
Iter 10000: loss=3954.1575, time=18.50s
iter 10000: dev acc=0.2334
Iter 11000: loss=4209.4086, time=20.40s
iter 11000: dev acc=0.2325
Iter 12000: loss=4179.7182, time=22.30s
iter 12000: dev acc=0.2298
Iter 13000: loss=4052.7441, time=24.20s
iter 13000: dev acc=0.2371
new highscore
Iter 14000: loss=3909.1481, time=26.10s
iter 14000: dev acc=0.2371
Iter 15000: loss=4024.2681, time=28.00s
iter 15000: dev acc=0.2307
Iter 16000: loss=4047.1393, time=29.90s
iter 16000: dev acc=0.2334
Iter 17000: loss=3726.2105, time=31.80s
iter 17000: dev acc=0.2343
Iter 18000: loss=3639.7389, time=33.71s
iter 18000: dev acc=0.2361
Iter 19000: loss=3767.6274, time=35.61s
iter 19000: dev acc=0.2398
new highscore
Iter 20000: loss=3524.7754, time=37.52s
iter 20000: dev acc=0.2443
new highscore
Iter 21000: loss=3549.8197, time=39.43s
iter 21000: dev acc=0.2461
new highscore
Iter 22000: loss=3403.4067, time=41.33s
iter 22000: dev acc=0.2443
Iter 23000: loss=3410.2641, time=43.23s
iter 23000: dev acc=0.2470
new highscore
Iter 24000: loss=3488.5155, time=45.13s
iter 24000: dev acc=0.2461
Iter 25000: loss=3218.4755, time=47.03s
iter 25000: dev acc=0.2480
new highscore
Iter 26000: loss=3418.8354, time=48.92s
iter 26000: dev acc=0.2489
new highscore
Iter 27000: loss=3102.5987, time=50.82s
iter 27000: dev acc=0.2552
new highscore
Iter 28000: loss=3055.5814, time=52.72s
iter 28000: dev acc=0.2607
new highscore
Iter 29000: loss=3035.5668, time=54.62s
iter 29000: dev acc=0.2607
Iter 30000: loss=3152.0929, time=56.52s
iter 30000: dev acc=0.2579
Done training
Loading best model
best model iter 28000: train acc=0.3056, dev acc=0.2607, test acc=0.2769
losses:
[5250.558789235695, 4960.6557825046575, 4653.307206117461, 4878.203203856436, 4674.402268222797, 4545.435991909882, 4379.354578130333, 4478.002407953056, 4317.034790137393, 3954.1575129562116, 4209.40859306954, 4179.718239549866, 4052.7440522510196, 3909.148110207614, 4024.2681291387453, 4047.139262229397, 3726.2105125834614, 3639.738865434363, 3767.6274346078544, 3524.7754120750214, 3549.819653663846, 3403.4067043256873, 3410.264087090023, 3488.515545514474, 3218.47550148773, 3418.835402847835, 3102.59870942443, 3055.581367297822, 3035.5668409566388, 3152.0928626017194]
accuracies:
[0.1989100817438692, 0.20708446866485014, 0.20708446866485014, 0.2134423251589464, 0.22252497729336967, 0.22797456857402362, 0.23160762942779292, 0.23342415985467757, 0.23342415985467757, 0.23342415985467757, 0.23251589464123523, 0.22979109900090827, 0.23705722070844687, 0.23705722070844687, 0.23069936421435058, 0.23342415985467757, 0.23433242506811988, 0.23614895549500453, 0.23978201634877383, 0.24432334241598547, 0.24613987284287012, 0.24432334241598547, 0.24704813805631246, 0.24613987284287012, 0.24795640326975477, 0.2488646684831971, 0.25522252497729336, 0.26067211625794734, 0.26067211625794734, 0.2579473206176203]

BOW(
  (embed): Embedding(18280, 5)
)
Iter 1000: loss=5445.8817, time=1.18s
iter 1000: dev acc=0.2189
new highscore
Iter 2000: loss=5068.4751, time=3.10s
iter 2000: dev acc=0.2180
Iter 3000: loss=4865.0571, time=5.03s
iter 3000: dev acc=0.2216
new highscore
Iter 4000: loss=4842.5168, time=6.95s
iter 4000: dev acc=0.2225
new highscore
Iter 5000: loss=4735.4229, time=8.87s
iter 5000: dev acc=0.2252
new highscore
Iter 6000: loss=4686.6436, time=10.79s
iter 6000: dev acc=0.2307
new highscore
Iter 7000: loss=4687.1132, time=12.72s
iter 7000: dev acc=0.2316
new highscore
Iter 8000: loss=4516.9586, time=14.62s
iter 8000: dev acc=0.2361
new highscore
Iter 9000: loss=4527.2872, time=16.54s
iter 9000: dev acc=0.2343
Iter 10000: loss=4465.2433, time=18.43s
iter 10000: dev acc=0.2361
Iter 11000: loss=4108.0804, time=20.34s
iter 11000: dev acc=0.2343
Iter 12000: loss=3947.6774, time=22.25s
iter 12000: dev acc=0.2361
Iter 13000: loss=4067.9194, time=24.16s
iter 13000: dev acc=0.2371
new highscore
Iter 14000: loss=4075.5006, time=26.07s
iter 14000: dev acc=0.2416
new highscore
Iter 15000: loss=3946.5226, time=27.97s
iter 15000: dev acc=0.2452
new highscore
Iter 16000: loss=4065.2877, time=29.88s
iter 16000: dev acc=0.2452
Iter 17000: loss=3804.9383, time=31.77s
iter 17000: dev acc=0.2452
Iter 18000: loss=3723.6772, time=33.68s
iter 18000: dev acc=0.2461
new highscore
Iter 19000: loss=3464.2993, time=35.59s
iter 19000: dev acc=0.2489
new highscore
Iter 20000: loss=3827.4417, time=37.49s
iter 20000: dev acc=0.2452
Iter 21000: loss=3637.8725, time=39.39s
iter 21000: dev acc=0.2480
Iter 22000: loss=3612.9859, time=41.30s
iter 22000: dev acc=0.2443
Iter 23000: loss=3371.6593, time=43.20s
iter 23000: dev acc=0.2480
Iter 24000: loss=3397.8585, time=45.10s
iter 24000: dev acc=0.2489
Iter 25000: loss=3240.4563, time=46.99s
iter 25000: dev acc=0.2507
new highscore
Iter 26000: loss=3648.6274, time=48.91s
iter 26000: dev acc=0.2480
Iter 27000: loss=3161.0256, time=50.81s
iter 27000: dev acc=0.2516
new highscore
Iter 28000: loss=3213.6743, time=52.71s
iter 28000: dev acc=0.2570
new highscore
Iter 29000: loss=3308.6964, time=54.61s
iter 29000: dev acc=0.2534
Iter 30000: loss=3145.5934, time=56.51s
iter 30000: dev acc=0.2534
Done training
Loading best model
best model iter 28000: train acc=0.3121, dev acc=0.2570, test acc=0.2430
losses:
[5445.881689986195, 5068.475088856776, 4865.057072147027, 4842.516814234505, 4735.422863977149, 4686.643581552335, 4687.11318762808, 4516.958635813826, 4527.2871900846, 4465.243304499594, 4108.080398753426, 3947.677351987773, 4067.919414543218, 4075.50059134794, 3946.522623432189, 4065.287738997118, 3804.9382783895244, 3723.677200676915, 3464.299338275883, 3827.44165324423, 3637.872539695629, 3612.9859408299053, 3371.659292837201, 3397.858486445979, 3240.456265944993, 3648.6274135004023, 3161.025601124903, 3213.6742662633733, 3308.6963668174867, 3145.593448381912]
accuracies:
[0.21889191643960038, 0.21798365122615804, 0.22161671207992734, 0.22252497729336967, 0.22524977293369663, 0.23069936421435058, 0.23160762942779292, 0.23614895549500453, 0.23433242506811988, 0.23614895549500453, 0.23433242506811988, 0.23614895549500453, 0.23705722070844687, 0.24159854677565848, 0.2452316076294278, 0.2452316076294278, 0.2452316076294278, 0.24613987284287012, 0.2488646684831971, 0.2452316076294278, 0.24795640326975477, 0.24432334241598547, 0.24795640326975477, 0.2488646684831971, 0.2506811989100817, 0.24795640326975477, 0.25158946412352406, 0.25703905540417804, 0.25340599455040874, 0.25340599455040874]

